# 聊天机器人

## 给定身份

* 通过 `role 来区分角色`
1. `system: 系统提示词(给ai agent预设身份)`
2. `user: 用户输入`
3. `assistant: 模型的输出`

```ipynb
import os

from openai import OpenAI
from dotenv import load_dotenv
# 表格是以 HTML 格式呈现的，加载出来
from IPython.display import display, HTML

# 加载 .env 文件
load_dotenv()

client = OpenAI(
    # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key="sk-xxx",
    api_key=os.getenv("DASHSCOPE_API_KEY"),  # 如何获取API Key：https://help.aliyun.com/zh/model-studio/developer-reference/get-api-key
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

completion = client.chat.completions.create(
    model="deepseek-v3",  # 模型. deepseek-v3没有思考过程，直接给出答案; deepseek-r1会给出思考过程
    messages=[
        # 通过role 来区分角色
        # system: 系统提示词(给ai agent预设身份)
        # user: 用户输入
        # assistant: 模型的输出
        {'role':'system', 'content':'你是一个像莎士比亚一样说话的助手。'},    
        {'role':'user', 'content':'给我讲个笑话'},   
        {'role':'assistant', 'content':'鸡为什么过马路'},   
        {'role':'user', 'content':'我不知道'}  
    ],
    temperature=0
)

response = completion.choices[0].message.content

display(HTML(response))
```

## 构建上下文

```ipynb
import os

from openai import OpenAI
from dotenv import load_dotenv
# 表格是以 HTML 格式呈现的，加载出来
from IPython.display import display, HTML

# 加载 .env 文件
load_dotenv()

client = OpenAI(
    # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key="sk-xxx",
    api_key=os.getenv("DASHSCOPE_API_KEY"),  # 如何获取API Key：https://help.aliyun.com/zh/model-studio/developer-reference/get-api-key
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)
# 中文
messages =  [  
{'role':'system', 'content':'你是个友好的聊天机器人。'},
{'role':'user', 'content':'Hi, 我是Isa'},
{'role':'assistant', 'content': "Hi Isa! 很高兴认识你。今天有什么可以帮到你的吗?"},
{'role':'user', 'content':'是的，你可以提醒我, 我的名字是什么?'}  ]

completion = client.chat.completions.create(
    model="deepseek-v3",  # 模型. deepseek-v3没有思考过程，直接给出答案; deepseek-r1会给出思考过程
    messages=messages,
    temperature=0
)

response = completion.choices[0].message.content

display(HTML(response))
```

* 这其实就是上下文,在模型的输入中提供早期的交流。我们将其称为上下文 (context) 。
* 因为模型有了需要的全部上下文，所以它能够做出回应，就像我们在输入的消息列表中看到的一样。



